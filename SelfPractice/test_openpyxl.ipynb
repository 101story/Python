{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "\n",
    "wb = Workbook()\n",
    "ws = wb.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_sheet\n"
     ]
    }
   ],
   "source": [
    "created_sheet = wb.create_sheet(title='create_sheet')\n",
    "print(created_sheet.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws2 = wb.create_sheet(\"Mysheet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws3 = wb.create_sheet(\"My Last sheet\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.title = \"New Title\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws1 = wb[\"New Title\"]  # it's set before when you set ws.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New Title', 'My Last sheet', 'Mysheet']\n"
     ]
    }
   ],
   "source": [
    "print(wb.sheetnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Title\n",
      "My Last sheet\n",
      "Mysheet\n"
     ]
    }
   ],
   "source": [
    "for sh in wb:\n",
    "    print(sh.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = ws['A4']\n",
    "ws1['A1'] = 'first'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <Cell 'New Title'.A2>\n",
      "1 <Cell 'New Title'.B2>\n",
      "2 <Cell 'New Title'.C2>\n",
      "0 <Cell 'New Title'.A3>\n",
      "1 <Cell 'New Title'.B3>\n",
      "2 <Cell 'New Title'.C3>\n"
     ]
    }
   ],
   "source": [
    "cell_range = ws1['A2':'C3'] \n",
    "for i, row in enumerate(cell_range):\n",
    "    for i, c in enumerate(row):\n",
    "        print(i, c)\n",
    "        c.value = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.save('test_openpyxl.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deepbrain excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 % 1 send_socket for progress.......\n",
      "1 % 1 send_socket for progress.......\n",
      "2 % 1 send_socket for progress.......\n",
      "./1_20221221_132727.325322.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "from openpyxl import Workbook\n",
    "import datetime\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Patient:\n",
    "    name: str\n",
    "    pid: int\n",
    "    sex: str\n",
    "    age: int\n",
    "    t2w_zip_path: str\n",
    "    # WMH: str\n",
    "    # WM: str\n",
    "    # TIV: str\n",
    "    t1w_zip_path:str\n",
    "    # json_path:str\n",
    "    # large_json_path: str\n",
    "    # thick_json_path:str\n",
    "    # shape_json_path:str\n",
    "\n",
    "\n",
    "patient_list = [\n",
    "    Patient(name='a', pid=1, sex='f', age=10, t2w_zip_path=None, t1w_zip_path=None),\n",
    "    Patient(name='b', pid=2, sex='m', age=13, t2w_zip_path=None, t1w_zip_path=None),\n",
    "    Patient(name='c', pid=3, sex='m', age=19, t2w_zip_path=None, t1w_zip_path=None)\n",
    "]\n",
    "user_id = 1\n",
    "\n",
    "wb = Workbook(write_only=True)\n",
    "sheet_list = []\n",
    "sheet_list.append(wb.create_sheet(title='volume'))\n",
    "sheet_list.append(wb.create_sheet(title='volume normative percentile'))\n",
    "sheet_list.append(wb.create_sheet(title='ICV'))\n",
    "sheet_list.append(wb.create_sheet(title='ICV normative percentile'))\n",
    "sheet_list.append(wb.create_sheet(title='radiomics feature'))\n",
    "sheet_list.append(wb.create_sheet(title='cortical thickness'))\n",
    "sheet_list.append(wb.create_sheet(title='cortical thickness np'))\n",
    "sheet_list.append(wb.create_sheet(title='wmh'))\n",
    "# asset_path = os.path.join(base_path, BaseConfig.ASSET_PATH)\n",
    "name_list = []\n",
    "asset_path = './'\n",
    "\n",
    "with open(os.path.join(asset_path, 'name.txt'), 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        name_list.append(line.strip('\\n').split(','))\n",
    "header = ['Name', 'ID', 'Sex', 'Age', 'Birth Date', 'Study Date', 'Analysis Date']\n",
    "shape_list = [\n",
    "    'Sphericity',\n",
    "    'Maximum3DDiameter',\n",
    "    'LeastAxisLength',\n",
    "    'Maximum2DDiameterColumn',\n",
    "    'SurfaceArea',\n",
    "    'Maximum2DDiameterSlice',\n",
    "    'Elongation',\n",
    "    'SurfaceVolumeRatio',\n",
    "    'Flatness',\n",
    "    'MajorAxisLength',\n",
    "    'VoxelVolume',\n",
    "    'MeshVolume',\n",
    "    'MinorAxisLength',\n",
    "    'Maximum2DDiameterRow'\n",
    "]\n",
    "\n",
    "shape_name_list = []\n",
    "with open(os.path.join(asset_path, 'shape.txt'), 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        shape_name_list.append(line.strip('\\n'))\n",
    "\n",
    "shape_header = ['Name', 'ID', 'Sex', 'Age', 'Birth Date', 'Study Date', 'Analysis Date']\n",
    "for name in shape_name_list:\n",
    "    for shape in shape_list:\n",
    "        shape_header += [name + ' / ' + shape]\n",
    "for name, _ in name_list:\n",
    "    header += [name + ' left']\n",
    "    header += [name + ' right']\n",
    "    header += [name + ' total']\n",
    "wmh_header = ['Name', 'ID', 'Sex', 'Age', 'Birth Date', 'Study Date', 'Analysis Date',\n",
    "                'WMH volume', 'WM volume', 'TIV', '(WMH volume) / (WM volume)']\n",
    "for i in range(8):\n",
    "    if i == 4:\n",
    "        sheet_list[i].append(shape_header)\n",
    "    elif i == 7:\n",
    "        sheet_list[i].append(wmh_header)\n",
    "    else:\n",
    "        sheet_list[i].append(header)\n",
    "step = int(len(patient_list) / 10) if len(patient_list) > 10 else 1\n",
    "\n",
    "for idx, patient in enumerate(patient_list):\n",
    "    if idx % step == 0:\n",
    "        print(f'{idx} % {step} send_socket for progress.......')\n",
    "        # self._send_socket('export_doing', {\n",
    "        #     'user_id': user_id,\n",
    "        #     'percent': int((100 * idx) / len(patient_list))\n",
    "        # })\n",
    "    data_list = []\n",
    "    for sheet in sheet_list:\n",
    "        data_list.append([\n",
    "            patient.name,\n",
    "            patient.pid,\n",
    "            patient.sex,\n",
    "            patient.age,\n",
    "            '', # patient.date_of_birth.strftime('%Y-%m-%d') if patient.date_of_birth is not None else '',\n",
    "            '', # patient.date_of_study.strftime('%Y-%m-%d') if patient.date_of_study is not None else '',\n",
    "            '' # patient.date_of_analysis.strftime('%Y-%m-%d') if patient.date_of_analysis is not None else ''\n",
    "        ])\n",
    "    if patient.t2w_zip_path is not None:\n",
    "        WMH = patient.WMH\n",
    "        WM = patient.WM\n",
    "        TIV = patient.TIV\n",
    "        data_list[7] += [\n",
    "            WMH if WMH else '-',\n",
    "            WM if WM else '-',\n",
    "            TIV if TIV else '-',\n",
    "            WMH / (WM / 1000) if WMH and WM else '-'\n",
    "        ]\n",
    "    else:\n",
    "        data_list[7] += ['-', '-', '-', '-']\n",
    "    if patient.t1w_zip_path is not None:\n",
    "        old_json_data = json.load(open(patient.json_path, 'r'))\n",
    "        large_data = json.load(open(patient.large_json_path, 'r'))\n",
    "        old_ct_data = eval(json.load(open(patient.thick_json_path, 'r')))\n",
    "        old_shape_data = json.load(open(patient.shape_json_path, 'r'))\n",
    "\n",
    "        json_data = []\n",
    "        idx_map = {}\n",
    "        for i, r in enumerate(old_json_data):\n",
    "            idx_map[r['brain_regions']] = ('small', i)\n",
    "        for i, r in enumerate(large_data):\n",
    "            idx_map[r['brain_regions']] = ('large', i)\n",
    "        for _, key in name_list:\n",
    "            text, i = idx_map[key]\n",
    "            if text == 'small':\n",
    "                json_data.append(old_json_data[i])\n",
    "            else:\n",
    "                json_data.append(large_data[i])\n",
    "\n",
    "        ct_data = []\n",
    "        idx_map = {}\n",
    "        for i, r in enumerate(old_ct_data):\n",
    "            idx_map[r['brain_regions']] = i\n",
    "        for _, key in name_list:\n",
    "            if key in idx_map:\n",
    "                ct_data.append(old_ct_data[idx_map[key]])\n",
    "            else:\n",
    "                ct_data.append({\n",
    "                    'brain_regions': key,\n",
    "                    'cortical_thickness_left': -1,\n",
    "                    'cortical_thickness_right': -1,\n",
    "                    'cortical_thickness_total': -1,\n",
    "                    'np_cortical_thickness_left': -1,\n",
    "                    'np_cortical_thickness_right': -1,\n",
    "                    'np_cortical_thickness_total': -1\n",
    "                })\n",
    "        shape_data = []\n",
    "        idx_map = {}\n",
    "        for i, r in enumerate(old_shape_data):\n",
    "            idx_map[r['brain_regions']] = i\n",
    "        for name in shape_name_list:\n",
    "            if name in idx_map:\n",
    "                shape_data.append(old_shape_data[idx_map[name]])\n",
    "            else:\n",
    "                temp = {}\n",
    "                for shape in shape_list:\n",
    "                    temp[shape] = '-'\n",
    "                shape_data.append(temp)\n",
    "\n",
    "        for part in json_data:\n",
    "            if part['brain_regions'] == 'vessel':\n",
    "                continue\n",
    "            data_list[0] += [part['volume_left'] / 1000] if part['volume_left'] >= 0 else ['-']\n",
    "            data_list[0] += [part['volume_right'] / 1000] if part['volume_right'] >= 0 else ['-']\n",
    "            data_list[0] += [part['volume_total'] / 1000] if part['volume_total'] >= 0 else ['-']\n",
    "            data_list[1] += [part['np_volume_left']] if part['np_volume_left'] >= 0 else ['-']\n",
    "            data_list[1] += [part['np_volume_right']] if part['np_volume_right'] >= 0 else ['-']\n",
    "            data_list[1] += [part['np_volume_total']] if part['np_volume_total'] >= 0 else ['-']\n",
    "            data_list[2] += [part['icv_left'] * 100] if part['icv_left'] >= 0 else ['-']\n",
    "            data_list[2] += [part['icv_right'] * 100] if part['icv_right'] >= 0 else ['-']\n",
    "            data_list[2] += [part['icv_total'] * 100] if part['icv_total'] >= 0 else ['-']\n",
    "            data_list[3] += [part['np_icv_left']] if part['np_icv_left'] >= 0 else ['-']\n",
    "            data_list[3] += [part['np_icv_right']] if part['np_icv_right'] >= 0 else ['-']\n",
    "            data_list[3] += [part['np_icv_total']] if part['np_icv_total'] >= 0 else ['-']\n",
    "        for part in ct_data:\n",
    "            if part['brain_regions'] == 'vessel':\n",
    "                continue\n",
    "            data_list[5] += [part['cortical_thickness_left']\n",
    "                                ] if part['cortical_thickness_left'] >= 0 else ['-']\n",
    "            data_list[5] += [part['cortical_thickness_right']\n",
    "                                ] if part['cortical_thickness_right'] >= 0 else ['-']\n",
    "            data_list[5] += [part['cortical_thickness_total']\n",
    "                                ] if part['cortical_thickness_total'] >= 0 else ['-']\n",
    "            data_list[6] += [part['np_cortical_thickness_left']\n",
    "                                ] if part['np_cortical_thickness_left'] >= 0 else ['-']\n",
    "            data_list[6] += [part['np_cortical_thickness_right']\n",
    "                                ] if part['np_cortical_thickness_right'] >= 0 else ['-']\n",
    "            data_list[6] += [part['np_cortical_thickness_total']\n",
    "                                ] if part['np_cortical_thickness_total'] >= 0 else ['-']\n",
    "\n",
    "        for shape_dic in shape_data:\n",
    "            for shape in shape_list:\n",
    "                data_list[4] += [shape_dic[shape]]\n",
    "    else:\n",
    "        for i in range(8):\n",
    "            if i == 4:\n",
    "                data_list[i] += ['-'] * 224\n",
    "            elif i != 7:\n",
    "                data_list[i] += ['-'] * 189\n",
    "    for i in range(len(data_list)):\n",
    "        sheet_list[i].append(data_list[i])\n",
    "excel_name = str(user_id) + '_' + \\\n",
    "    datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S.%f\") + '.xlsx'\n",
    "excel_path = os.path.join(asset_path, excel_name)\n",
    "wb.save(excel_path)\n",
    "print(excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volumn\n",
      "['header 2', 'header 2', 'header 2', 'header 2', 'header 2', 'header 2', 'header 2', 'header 2', 'header 2', 'header 2'] 10\n",
      "['info', 'info', 'info'] 3\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "from openpyxl import Workbook\n",
    "# from core.const.enum import BaseEnum\n",
    "from enum import EnumMeta\n",
    "\n",
    "\n",
    "class excel_sheet_title(EnumMeta):\n",
    "    volumn = 'volumn'\n",
    "    volumn_normative = 'volume normative percentile'\n",
    "    ICV = 'ICV'\n",
    "    ICV_normative = 'ICV normative percentile'\n",
    "    radiomics = 'radiomics feature'\n",
    "    cortical = 'cortical thickness'\n",
    "    cortical_np = 'cortical thickness np'\n",
    "    wmh = 'wmh'\n",
    "\n",
    "print(excel_sheet_title.volumn)\n",
    "wb = Workbook(write_only=True)\n",
    "wb_volume = wb.create_sheet(title=excel_sheet_title.volumn)\n",
    "wb_volumn_normative = wb.create_sheet(title=excel_sheet_title.volumn_normative)\n",
    "wb_ICV = wb.create_sheet(title=excel_sheet_title.ICV)\n",
    "\n",
    "sheets = [wb_volume, wb_volumn_normative, wb_ICV]\n",
    "\n",
    "for i, sheet in enumerate(sheets):\n",
    "    headers = [f'header {i}']*10\n",
    "    sheet.append(headers)\n",
    "\n",
    "# for sheet in sheets:\n",
    "#     sheet.append(['info']*3)\n",
    "\n",
    "count_defualt = len(headers) - len(patient)\n",
    "\n",
    "print(headers, len(headers))\n",
    "print(patient, len(patient))\n",
    "print(count_defualt)\n",
    "\n",
    "for i in range(0, 20):\n",
    "    patient = ['info']*3\n",
    "    default_data = ['-'] * count_defualt\n",
    "    wb_volume.append(patient + list(range(7)))\n",
    "    wb_volumn_normative.append(patient + default_data)\n",
    "    wb_ICV.append(patient + list(range(7)))\n",
    "\n",
    "\n",
    "wb.save('test_openpyxl.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4], [0, 1, 2, 3, 4, 0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(range(5))\n",
    "b = a.copy()\n",
    "b.extend(list(range(5)))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 3]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2] + [1,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 % 1 send_socket for progress.......\n",
      "1 % 1 send_socket for progress.......\n",
      "2 % 1 send_socket for progress.......\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "from openpyxl import Workbook\n",
    "import datetime\n",
    "from enum import EnumMeta\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Patient:\n",
    "    name: str\n",
    "    pid: int\n",
    "    sex: str\n",
    "    age: int\n",
    "    t2w_zip_path: str\n",
    "    # WMH: str\n",
    "    # WM: str\n",
    "    # TIV: str\n",
    "    t1w_zip_path:str\n",
    "    # json_path:str\n",
    "    # large_json_path: str\n",
    "    # thick_json_path:str\n",
    "    # shape_json_path:str\n",
    "\n",
    "\n",
    "patient_list = [\n",
    "    Patient(name='a', pid=1, sex='f', age=10, t2w_zip_path=None, t1w_zip_path=None),\n",
    "    Patient(name='b', pid=2, sex='m', age=13, t2w_zip_path=None, t1w_zip_path=None),\n",
    "    Patient(name='c', pid=3, sex='m', age=19, t2w_zip_path=None, t1w_zip_path=None)\n",
    "]\n",
    "user_id = 1\n",
    "\n",
    "\n",
    "class ExcelSheetTitles(EnumMeta):\n",
    "    volumn = 'volumn'\n",
    "    volumn_normative = 'volume normative percentile'\n",
    "    ICV = 'ICV'\n",
    "    ICV_normative = 'ICV normative percentile'\n",
    "    radiomics = 'radiomics feature'\n",
    "    cortical = 'cortical thickness'\n",
    "    cortical_np = 'cortical thickness np'\n",
    "    wmh = 'wmh'\n",
    "\n",
    "\n",
    "class ExcelResult:\n",
    "    def __init__(self, user_id, patient_list):\n",
    "        assert patient_list, 'patient list should not be empty!'\n",
    "        self.user_id = user_id\n",
    "        self.patient_list = patient_list\n",
    "\n",
    "    def _make_json_data(self, old_json_data, large_data, common_study_data_key):\n",
    "        json_data = []\n",
    "        idx_map = {}\n",
    "        for i, r in enumerate(old_json_data):\n",
    "            idx_map[r['brain_regions']] = ('small', i)\n",
    "        for i, r in enumerate(large_data):\n",
    "            idx_map[r['brain_regions']] = ('large', i)\n",
    "        for key in common_study_data_key:\n",
    "            text, i = idx_map[key]\n",
    "            if text == 'small':\n",
    "                json_data.append(old_json_data[i])\n",
    "            else:\n",
    "                json_data.append(large_data[i])\n",
    "        return json_data\n",
    "\n",
    "    def _make_ct_data(self, old_ct_data, common_study_data_key):\n",
    "        ct_data = []\n",
    "        idx_map = {}\n",
    "        for i, r in enumerate(old_ct_data):\n",
    "            idx_map[r['brain_regions']] = i\n",
    "        for key in common_study_data_key:\n",
    "            if key in idx_map:\n",
    "                ct_data.append(old_ct_data[idx_map[key]])\n",
    "            else:\n",
    "                ct_data.append({\n",
    "                    'brain_regions': key,\n",
    "                    'cortical_thickness_left': -1,\n",
    "                    'cortical_thickness_right': -1,\n",
    "                    'cortical_thickness_total': -1,\n",
    "                    'np_cortical_thickness_left': -1,\n",
    "                    'np_cortical_thickness_right': -1,\n",
    "                    'np_cortical_thickness_total': -1\n",
    "                })\n",
    "        return ct_data\n",
    "\n",
    "    def _make_shape_data(self, old_shape_data, radiomics_shape_list_group1, radiomics_shape_list_group2):\n",
    "        shape_data = []\n",
    "        idx_map = {}\n",
    "        for i, r in enumerate(old_shape_data):\n",
    "            idx_map[r['brain_regions']] = i\n",
    "        for name in radiomics_shape_list_group1:\n",
    "            if name in idx_map:\n",
    "                shape_data.append(old_shape_data[idx_map[name]])\n",
    "            else:\n",
    "                temp = {}\n",
    "                for shape in radiomics_shape_list_group2:\n",
    "                    temp[shape] = '-'\n",
    "                shape_data.append(temp)\n",
    "        return shape_data\n",
    "\n",
    "    def create_excel_result(self):\n",
    "        wb = Workbook(write_only=True)\n",
    "        wb_volume = wb.create_sheet(title=ExcelSheetTitles.volumn)\n",
    "        wb_volumn_normative = wb.create_sheet(title=ExcelSheetTitles.volumn_normative)\n",
    "        wb_ICV = wb.create_sheet(title=ExcelSheetTitles.ICV)\n",
    "        wb_ICV_normative = wb.create_sheet(title=ExcelSheetTitles.ICV_normative)\n",
    "        wb_radiomics = wb.create_sheet(title=ExcelSheetTitles.radiomics)\n",
    "        wb_cortical = wb.create_sheet(title=ExcelSheetTitles.cortical)\n",
    "        wb_cortical_np = wb.create_sheet(title=ExcelSheetTitles.cortical_np)\n",
    "        wb_wmh = wb.create_sheet(title=ExcelSheetTitles.wmh)\n",
    "\n",
    "        # ======== making haader =========\n",
    "\n",
    "        asset_path = './'  # FIXME\n",
    "        # asset_path = config.ASSET_PATH\n",
    "\n",
    "        common_study_data_name = []\n",
    "        common_study_data_key = []\n",
    "        with open(os.path.join(asset_path, 'name.txt'), 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                name, key = line.strip('\\n').split(',')\n",
    "                common_study_data_name.append(name)\n",
    "                common_study_data_key.append(key)\n",
    "\n",
    "        header_common = ['Name', 'ID', 'Sex', 'Age', 'Birth Date', 'Study Date', 'Analysis Date']\n",
    "\n",
    "        # common header\n",
    "        full_header_common = header_common.copy()\n",
    "        for shape_name in common_study_data_name:\n",
    "            full_header_common += [shape_name + ' left']\n",
    "            full_header_common += [shape_name + ' right']\n",
    "            full_header_common += [shape_name + ' total']\n",
    "\n",
    "        common_sheet_list = [\n",
    "            wb_volume, wb_volumn_normative, wb_ICV, wb_ICV_normative, wb_cortical, wb_cortical_np\n",
    "        ]\n",
    "        for sheet in common_sheet_list:\n",
    "            sheet.append(full_header_common)\n",
    "\n",
    "        # radiomics feature header\n",
    "        radiomics_shape_list_group1 = []\n",
    "        with open(os.path.join(asset_path, 'shape.txt'), 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                radiomics_shape_list_group1.append(line.strip('\\n'))\n",
    "\n",
    "        radiomics_shape_list_group2 = [\n",
    "            'Sphericity',\n",
    "            'Maximum3DDiameter',\n",
    "            'LeastAxisLength',\n",
    "            'Maximum2DDiameterColumn',\n",
    "            'SurfaceArea',\n",
    "            'Maximum2DDiameterSlice',\n",
    "            'Elongation',\n",
    "            'SurfaceVolumeRatio',\n",
    "            'Flatness',\n",
    "            'MajorAxisLength',\n",
    "            'VoxelVolume',\n",
    "            'MeshVolume',\n",
    "            'MinorAxisLength',\n",
    "            'Maximum2DDiameterRow'\n",
    "        ]\n",
    "\n",
    "        full_header_radiomics = header_common.copy()\n",
    "        for prefix in radiomics_shape_list_group1:\n",
    "            for subfix in radiomics_shape_list_group2:\n",
    "                full_header_radiomics += [prefix + ' / ' + subfix]\n",
    "\n",
    "        wb_radiomics.append(full_header_radiomics)\n",
    "\n",
    "        # wmh header\n",
    "        full_wmh_header = header_common.copy() + ['WMH volume', 'WM volume', 'TIV', '(WMH volume) / (WM volume)']\n",
    "        wb_wmh.append(full_wmh_header)\n",
    "\n",
    "        step = int(len(self.patient_list) / 10) if len(self.patient_list) > 10 else 1\n",
    "\n",
    "        # ======== filling cell data ========\n",
    "\n",
    "        for idx, patient in enumerate(self.patient_list):\n",
    "            if idx % step == 0:\n",
    "                print(f'{idx} % {step} send_socket for progress.......')\n",
    "                # FIXME\n",
    "                # self._send_socket('export_doing', {\n",
    "                #     'user_id': user_id,\n",
    "                #     'percent': int((100 * idx) / len(patient_list))\n",
    "                # })\n",
    "\n",
    "            patient_info = [\n",
    "                patient.name,\n",
    "                patient.pid,\n",
    "                patient.sex,\n",
    "                patient.age,\n",
    "                '', # patient.date_of_birth.strftime('%Y-%m-%d') if patient.date_of_birth is not None else '',\n",
    "                '', # patient.date_of_study.strftime('%Y-%m-%d') if patient.date_of_study is not None else '',\n",
    "                '', # patient.date_of_analysis.strftime('%Y-%m-%d') if patient.date_of_analysis is not None else ''\n",
    "            ]\n",
    "\n",
    "            volume_study_data = []\n",
    "            volume_normative_study_data = []\n",
    "            icv_study_data = []\n",
    "            icv_normative_study_data = []\n",
    "            radiomics_study_data = []\n",
    "            cortical_study_data = []\n",
    "            cortical_np_study_data = []\n",
    "            wmh_study_data = []\n",
    "\n",
    "            if patient.t1w_zip_path:\n",
    "                old_json_data = json.load(open(patient.json_path, 'r'))\n",
    "                large_data = json.load(open(patient.large_json_path, 'r'))\n",
    "                old_ct_data = eval(json.load(open(patient.thick_json_path, 'r')))\n",
    "                old_shape_data = json.load(open(patient.shape_json_path, 'r'))\n",
    "\n",
    "                json_data = self._make_json_data(old_json_data, large_data, common_study_data_key)\n",
    "                shape_data = self._make_shape_data(old_shape_data, radiomics_shape_list_group1, radiomics_shape_list_group2)\n",
    "                ct_data = self._make_ct_data(old_ct_data, common_study_data_key)\n",
    "\n",
    "                for part in json_data:\n",
    "                    if part['brain_regions'] == 'vessel':\n",
    "                        continue\n",
    "\n",
    "                    volume_study_data += [part['volume_left'] / 1000] if part['volume_left'] >= 0 else ['-']\n",
    "                    volume_study_data += [part['volume_right'] / 1000] if part['volume_right'] >= 0 else ['-']\n",
    "                    volume_study_data += [part['volume_total'] / 1000] if part['volume_total'] >= 0 else ['-']\n",
    "\n",
    "                    volume_normative_study_data += [part['np_volume_left']] if part['np_volume_left'] >= 0 else ['-']\n",
    "                    volume_normative_study_data += [part['np_volume_right']] if part['np_volume_right'] >= 0 else ['-']\n",
    "                    volume_normative_study_data += [part['np_volume_total']] if part['np_volume_total'] >= 0 else ['-']\n",
    "\n",
    "                    icv_study_data += [part['icv_left'] * 100] if part['icv_left'] >= 0 else ['-']\n",
    "                    icv_study_data += [part['icv_right'] * 100] if part['icv_right'] >= 0 else ['-']\n",
    "                    icv_study_data += [part['icv_total'] * 100] if part['icv_total'] >= 0 else ['-']\n",
    "\n",
    "                    icv_normative_study_data += [part['np_icv_left']] if part['np_icv_left'] >= 0 else ['-']\n",
    "                    icv_normative_study_data += [part['np_icv_right']] if part['np_icv_right'] >= 0 else ['-']\n",
    "                    icv_normative_study_data += [part['np_icv_total']] if part['np_icv_total'] >= 0 else ['-']\n",
    "\n",
    "                for shape_dic in shape_data:\n",
    "                    for shape in radiomics_shape_list_group2:\n",
    "                        radiomics_study_data += [shape_dic[shape]]\n",
    "\n",
    "                for part in ct_data:\n",
    "                    if part['brain_regions'] == 'vessel':\n",
    "                        continue\n",
    "\n",
    "                    cortical_study_data += [\n",
    "                        part['cortical_thickness_left']\n",
    "                    ] if part['cortical_thickness_left'] >= 0 else ['-']\n",
    "                    cortical_study_data += [\n",
    "                        part['cortical_thickness_right']\n",
    "                    ] if part['cortical_thickness_right'] >= 0 else ['-']\n",
    "                    cortical_study_data += [\n",
    "                        part['cortical_thickness_total']\n",
    "                    ] if part['cortical_thickness_total'] >= 0 else ['-']\n",
    "\n",
    "                    cortical_np_study_data += [\n",
    "                        part['np_cortical_thickness_left']\n",
    "                    ] if part['np_cortical_thickness_left'] >= 0 else ['-']\n",
    "                    cortical_np_study_data += [\n",
    "                        part['np_cortical_thickness_right']\n",
    "                    ] if part['np_cortical_thickness_right'] >= 0 else ['-']\n",
    "                    cortical_np_study_data += [\n",
    "                        part['np_cortical_thickness_total']\n",
    "                    ] if part['np_cortical_thickness_total'] >= 0 else ['-']\n",
    "            else:\n",
    "                # no t1w_zip_path to set '-'\n",
    "\n",
    "                count_common_data = len(full_header_common) - len(patient_info)\n",
    "                count_raiomics_data = len(full_header_radiomics) - len(patient_info)\n",
    "\n",
    "                volume_study_data = ['-'] * count_common_data\n",
    "                volume_normative_study_data = ['-'] * count_common_data\n",
    "                icv_study_data = ['-'] * count_common_data\n",
    "                icv_normative_study_data = ['-'] * count_common_data\n",
    "                cortical_study_data = ['-'] * count_common_data\n",
    "                cortical_np_study_data = ['-'] * count_common_data\n",
    "\n",
    "                radiomics_study_data = ['-'] * count_raiomics_data\n",
    "\n",
    "            if patient.t2w_zip_path:\n",
    "                WMH = patient.WMH\n",
    "                WM = patient.WM\n",
    "                TIV = patient.TIV\n",
    "                wmh_study_data += [\n",
    "                    WMH if WMH else '-',\n",
    "                    WM if WM else '-',\n",
    "                    TIV if TIV else '-',\n",
    "                    WMH / (WM / 1000) if WMH and WM else '-'\n",
    "                ]\n",
    "            else:\n",
    "                # no t2w_zip_path to set '-'\n",
    "                count_wmh_data = len(full_wmh_header) - len(patient_info)\n",
    "                wmh_study_data = ['-'] * count_wmh_data\n",
    "\n",
    "            wb_volume.append(patient_info + volume_study_data)\n",
    "            wb_volumn_normative.append(patient_info + volume_normative_study_data)\n",
    "            wb_ICV.append(patient_info + icv_study_data)\n",
    "            wb_ICV_normative.append(patient_info + icv_normative_study_data)\n",
    "            wb_radiomics.append(patient_info + radiomics_study_data)\n",
    "            wb_cortical.append(patient_info + cortical_study_data)\n",
    "            wb_cortical_np.append(patient_info + cortical_np_study_data)\n",
    "            wb_wmh.append(patient_info + wmh_study_data)\n",
    "\n",
    "        excel_name = str(self.user_id) + '_' + \\\n",
    "            datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S.%f\") + '.xlsx'\n",
    "        excel_path = os.path.join(asset_path, excel_name)\n",
    "        wb.save(excel_path)\n",
    "\n",
    "\n",
    "ExcelResult(user_id, patient_list).create_excel_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1,) + (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4a30931ce832a3e1959f19dbcfcbb18d7c314097a708a8f8c2473a18b4f8baa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
