{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AA', '39.48', '6/11/2007', '9:36am', '-0.18', '181800']\n",
      "['AIG', '71.38', '6/11/2007', '9:36am', '-0.15', '195500']\n",
      "['AXP', '62.58', '6/11/2007', '9:36am', '-0.46', '935000']\n",
      "['BA', '98.31', '6/11/2007', '9:36am', '+0.12', '104800']\n",
      "['C', '53.08', '6/11/2007', '9:36am', '-0.25', '360900']\n",
      "['CAT', '78.29', '6/11/2007', '9:36am', '-0.23', '225400']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Symbol='AA', Price='39.48', Date='6/11/2007', Time='9:36am', Change='-0.18', Volume='181800')\n",
      "Row(Symbol='AIG', Price='71.38', Date='6/11/2007', Time='9:36am', Change='-0.15', Volume='195500')\n",
      "Row(Symbol='AXP', Price='62.58', Date='6/11/2007', Time='9:36am', Change='-0.46', Volume='935000')\n",
      "Row(Symbol='BA', Price='98.31', Date='6/11/2007', Time='9:36am', Change='+0.12', Volume='104800')\n",
      "Row(Symbol='C', Price='53.08', Date='6/11/2007', Time='9:36am', Change='-0.25', Volume='360900')\n",
      "Row(Symbol='CAT', Price='78.29', Date='6/11/2007', Time='9:36am', Change='-0.23', Volume='225400')\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headings = next(f_csv)\n",
    "    Row = namedtuple('Row', headings)\n",
    "    for r in f_csv:\n",
    "        row = Row(*r)\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Change': '-0.18', 'Date': '6/11/2007', 'Volume': '181800', 'Symbol': 'AA', 'Price': '39.48', 'Time': '9:36am'}\n",
      "{'Change': '-0.15', 'Date': '6/11/2007', 'Volume': '195500', 'Symbol': 'AIG', 'Price': '71.38', 'Time': '9:36am'}\n",
      "{'Change': '-0.46', 'Date': '6/11/2007', 'Volume': '935000', 'Symbol': 'AXP', 'Price': '62.58', 'Time': '9:36am'}\n",
      "{'Change': '+0.12', 'Date': '6/11/2007', 'Volume': '104800', 'Symbol': 'BA', 'Price': '98.31', 'Time': '9:36am'}\n",
      "{'Change': '-0.25', 'Date': '6/11/2007', 'Volume': '360900', 'Symbol': 'C', 'Price': '53.08', 'Time': '9:36am'}\n",
      "{'Change': '-0.23', 'Date': '6/11/2007', 'Volume': '225400', 'Symbol': 'CAT', 'Price': '78.29', 'Time': '9:36am'}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.DictReader(f)\n",
    "    for row in f_csv:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = ['Symbol','Price', 'Date', 'Time=', 'Change', 'Volume']\n",
    "rows = [(\"AA\",39.48,\"6/11/2007\",\"9:36am\",-0.18,181800),\n",
    "       (\"AIG\",71.38,\"6/11/2007\",\"9:36am\",-0.15,195500),\n",
    "       (\"BA\",98.31,\"6/11/2007\",\"9:36am\",+0.12,104800),\n",
    "        (\"AXP\",62.58,\"6/11/2007\",\"9:36am\",-0.46,935000),]\n",
    "\n",
    "with open('stocks.csv', 'w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(rows)\n",
    "#     f_csv = csv.DicWriter(f, headers)\n",
    "#     f_csv.writeheader()\n",
    "#     f_csv.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Symbol='AA', Price='39.48', Date='6/11/2007', Time_='9:36am', Change='-0.18', Volume='181800')\n",
      "Row(Symbol='AIG', Price='71.38', Date='6/11/2007', Time_='9:36am', Change='-0.15', Volume='195500')\n",
      "Row(Symbol='BA', Price='98.31', Date='6/11/2007', Time_='9:36am', Change='0.12', Volume='104800')\n",
      "Row(Symbol='AXP', Price='62.58', Date='6/11/2007', Time_='9:36am', Change='-0.46', Volume='935000')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = [re.sub('[^a-zA-Z_]', '_', h) for h in next(f_csv)]\n",
    "    Row = namedtuple('Row', headers)\n",
    "    for r in f_csv:\n",
    "        row = Row(*r)\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800)\n",
      "('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500)\n",
      "('BA', 98.31, '6/11/2007', '9:36am', 0.12, 104800)\n",
      "('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000)\n"
     ]
    }
   ],
   "source": [
    "col_types = [str, float, str, str, float, int]\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        # Apply conversions to the row items\n",
    "        row = tuple(convert(value) for convert, value in zip(col_types, row))\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Change': -0.18, 'Date': '6/11/2007', 'Volume': 181800, 'Symbol': 'AA', 'Price': 39.48, 'Time=': '9:36am'}\n",
      "{'Change': -0.15, 'Date': '6/11/2007', 'Volume': 195500, 'Symbol': 'AIG', 'Price': 71.38, 'Time=': '9:36am'}\n",
      "{'Change': 0.12, 'Date': '6/11/2007', 'Volume': 104800, 'Symbol': 'BA', 'Price': 98.31, 'Time=': '9:36am'}\n",
      "{'Change': -0.46, 'Date': '6/11/2007', 'Volume': 935000, 'Symbol': 'AXP', 'Price': 62.58, 'Time=': '9:36am'}\n"
     ]
    }
   ],
   "source": [
    "field_types = [ ('Price', float),\n",
    "                ('Change', float),\n",
    "                ('Volume', int) ]\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        row.update((key, conversion(row[key])) \n",
    "                   for key, conversion in field_types)\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"price\": 345.12, \"name\": \"ACME\", \"shares\": 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "data = {\n",
    "    'name': 'ACME', \n",
    "    'shares': 100, \n",
    "    'price': 345.12\n",
    "}\n",
    "\n",
    "json_str = json.dumps(data)\n",
    "\n",
    "print(json_str)\n",
    "type(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'price': 345.12, 'name': 'ACME', 'shares': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = json.loads(json_str)\n",
    "print(data)\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    'a': True, \n",
    "    'b': 'Hello',\n",
    "    'c': None,\n",
    "    'd': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"a\": true, \"b\": \"Hello\", \"c\": null, \"d\": false}'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(d)\n",
    "type(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "# u = urlopen('http://search.twitter.com/search.json?q=python&rpp=5')\n",
    "# resp = json.loads(u.read().decode('utf-8'))\n",
    "\n",
    "u = {\n",
    "    \"people\": {\n",
    "        \"person\": [\n",
    "            {\n",
    "                \"name\": \"Peter\",\n",
    "                \"age\": 43,\n",
    "                \"sex\": \"male\"\n",
    "            }, {\n",
    "                \"name\": \"Zara\",\n",
    "                \"age\": 65,\n",
    "                \"sex\": \"female\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "type(u)\n",
    "resp = json.loads(json.dumps(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': {'person': [{'age': 43, 'name': 'Peter', 'sex': 'male'},\n",
      "                       {'age': 65, 'name': 'Zara', 'sex': 'female'}]}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('a', True), ('b', 'Hello'), ('c', None), ('d', False)])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "data = json.loads(json.dumps(d), object_pairs_hook=OrderedDict)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACME'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class JSONObject:\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n",
    "        \n",
    "data = json.loads(json_str, object_hook=JSONObject)\n",
    "data.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"people\": {\n",
      "        \"person\": [\n",
      "            {\n",
      "                \"sex\": \"male\",\n",
      "                \"name\": \"Peter\",\n",
      "                \"age\": 43\n",
      "            },\n",
      "            {\n",
      "                \"sex\": \"female\",\n",
      "                \"name\": \"Zara\",\n",
      "                \"age\": 65\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(resp, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"people\": {\"person\": [{\"age\": 43, \"name\": \"Peter\", \"sex\": \"male\"}, {\"age\": 65, \"name\": \"Zara\", \"sex\": \"female\"}]}}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(resp, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_instance(obj):\n",
    "    d = {'__classname__':type(obj).__name__}\n",
    "    d.update(vars(obj))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 알려지지 않은 클래스에 이름을 매핑하는 딕셔너리 \n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "classes = {\n",
    "    'Point': Point\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unserialize_object(d):\n",
    "    clasname = d.pop('__classname__', None)\n",
    "    if clasname:\n",
    "        cls = classes[clasname]\n",
    "        obj = cls.__new__(cls) # __init__ 호출하지 않고 인스턴스 만들기 \n",
    "        for key, value in d.items():\n",
    "            setattr(obj, key, value)\n",
    "            return obj\n",
    "    else:\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"x\": 3, \"y\": 4, \"__classname__\": \"Point\"}'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Point at 0x7f659188aa20>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "AttributeError",
     "evalue": "'Point' object has no attribute 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-489ebd69265a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Point' object has no attribute 'y'"
     ]
    }
   ],
   "source": [
    "p = Point(3,4)\n",
    "s = json.dumps(p, default=serialize_instance)\n",
    "s\n",
    "\n",
    "a = json.loads(s, object_hook=unserialize_object)\n",
    "a\n",
    "a.x\n",
    "a.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xml.etree.ElementTree\n",
    "* simple xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mike Driscoll: PyDev of the Week: Qumisha Goss\n",
      "Mon, 18 Jun 2018 05:05:08 +0000\n",
      "http://www.blog.pythonlibrary.org/2018/06/18/qumisha-goss/\n",
      "\n",
      "Marcos Dione: identity-countries-languages-and-currencies\n",
      "Sun, 17 Jun 2018 16:06:01 +0000\n",
      "http://www.grulic.org.ar/~mdione/glob//posts/identity-countries-languages-and-currencies/\n",
      "\n",
      "Python Piedmont Triad User Group: PYPTUG Monthly meeting: Wrangling Geospatial Data\n",
      "Sun, 17 Jun 2018 14:02:46 +0000\n",
      "http://www.pyptug.org/2018/06/pyptug-monthly-meeting-wrangling.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from xml.etree.ElementTree import parse\n",
    "\n",
    "# Download the RSS feed and parse it\n",
    "u = urlopen('http://planet.python.org/rss20.xml')\n",
    "doc = parse(u)\n",
    "\n",
    "# Extract and output tags of interest\n",
    "for idx, item in enumerate(doc.iterfind('channel/item')):\n",
    "    title = item.findtext('title')\n",
    "    date = item.findtext('pubDate')\n",
    "    link = item.findtext('link')\n",
    "\n",
    "    print(title)\n",
    "    print(date)\n",
    "    print(link)\n",
    "    print()\n",
    "    \n",
    "    if idx == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xml.etree.ElementTree.ElementTree at 0x7f6590a10080>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'title' at 0x7f6590a0f368>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = doc.find('channel/title')\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'title'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Planet Python'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.get('some_attribute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big XML \n",
    "* 큰 xml 파일에서 최소의 메모리만 사용하여 데이터 추출  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import iterparse\n",
    "\n",
    "def parse_and_remove(filename, path):\n",
    "    path_parts = path.split('/')\n",
    "    doc = iterparse(filename, ('start', 'end'))\n",
    "    # Skip the root element\n",
    "    next(doc)\n",
    "\n",
    "    tag_stack = []\n",
    "    elem_stack = []\n",
    "    for event, elem in doc:\n",
    "        if event == 'start':\n",
    "            tag_stack.append(elem.tag)\n",
    "            elem_stack.append(elem)\n",
    "        elif event == 'end':\n",
    "            if tag_stack == path_parts:\n",
    "                yield elem\n",
    "                elem_stack[-2].remove(elem)\n",
    "            try:\n",
    "                tag_stack.pop()\n",
    "                elem_stack.pop()\n",
    "            except IndexError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start 이벤트는 요소가 처음 생성되었지만 다른 데이터가 (다른 자식요소) 를 만들지 않았을 때 생성된다. \n",
    "end 이벤트는 요소를 마쳤을 때 생성된다. \n",
    "\n",
    "스택은 계층구조, 요청 경로에 쇼소가 매칭하는지 판단하는데 사용된다. \n",
    "\n",
    "매칭을 발견하면 yield 로 호출자에게 다시 분출 한다. \n",
    "\n",
    "elem_stack[-2].remove(elem) 메모리를 절약하게 하는 부분이다. 앞에서 나온 요소를 부모로 부터 제거하는 역할을 한다. \n",
    "\n",
    "단, 실행 속도가 느리다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60617 13\n",
      "60626 8\n",
      "60651 7\n",
      "60623 6\n",
      "60647 6\n",
      "60613 4\n",
      "60628 4\n",
      "60609 4\n",
      "60636 4\n",
      "60625 4\n",
      "60657 3\n",
      "60641 3\n",
      "60622 3\n",
      "60619 3\n",
      "60629 3\n",
      "60638 2\n",
      "60656 2\n",
      "60644 2\n",
      "60649 2\n",
      "60618 2\n",
      "60654 2\n",
      "60612 1\n",
      "60652 1\n",
      "60643 1\n",
      "60660 1\n",
      "60632 1\n",
      "60637 1\n",
      "60707 1\n",
      "60616 1\n",
      "60614 1\n",
      "60631 1\n",
      "60639 1\n",
      "60634 1\n",
      "60630 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "potholes_by_zip = Counter()\n",
    "\n",
    "data = parse_and_remove('potholes.xml', 'row/row')\n",
    "for pothole in data:\n",
    "    potholes_by_zip[pothole.findtext('zip')] += 1\n",
    "\n",
    "for zipcode, num in potholes_by_zip.most_common():\n",
    "    print(zipcode, num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dict to xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import Element\n",
    "\n",
    "def dict_to_xml(tag, d):\n",
    "    elem = Element(tag)\n",
    "    for key, val in d.items():\n",
    "        child = Element(key)\n",
    "        child.text = str(val)\n",
    "        elem.append(child)\n",
    "    return elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'stock' at 0x7f65908f56d8>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = {\n",
    "    'name': 'ACME', \n",
    "    'shares': 100, \n",
    "    'price': 345.12\n",
    "}\n",
    "\n",
    "e = dict_to_xml('stock', s)\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<stock><price>345.12</price><name>ACME</name><shares>100</shares></stock>'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.etree.ElementTree import tostring\n",
    "tostring(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<stock _id=\"1234\"><price>345.12</price><name>ACME</name><shares>100</shares></stock>'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.set('_id', '1234')\n",
    "tostring(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_xml_str(tag, d):\n",
    "    parts = ['<{}>'.format(tag)]\n",
    "    for key, val in d.items():\n",
    "        parts.append('<{0}>{1}</{0}>'.format(key, val))\n",
    "    parts.append('</{}>'.format(tag))\n",
    "    return ''.join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<item><name><spam></name></item>'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'name':'<spam>'}\n",
    "dict_to_xml_str('item', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<item><name>&lt;spam&gt;</name></item>'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = dict_to_xml('item', d)\n",
    "tostring(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "& lt;spam & gt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&lt;spam&gt;'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xml.sax.saxutils import escape, unescape\n",
    "escape('<spam>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<spam>'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unescape(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xml parsing, modifing, saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import parse, Element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'stop' at 0x7fa71ee2c778>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = parse('pred.xml')\n",
    "root = doc.getroot()\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.remove(root.find('sri')) # 요소 제거 \n",
    "root.getchildren().index(root.find('nm')) # nm 뒤에 요소 몇개 삽입 하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Element('spam')\n",
    "e.text = 'This is a test'\n",
    "root.insert(2, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.write('newpred.xml', xml_declaration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'spam' at 0x7fa71eb19db8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.find('spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xml namespace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14791'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.findtext('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'pre' at 0x7fa71ee2c9f8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.find('pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.find('stop/id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.find('stop/{http://www.w3.org/1999}cr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XMLNamespaces:\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        self.namespaces = {}\n",
    "        for name, uri in kwargs.items():\n",
    "            self.register(name, uri)\n",
    "    \n",
    "    def register(self, name, uri):\n",
    "        self.namespaces[name] = '{'+uri+'}'\n",
    "    \n",
    "    def __call__(self, path):\n",
    "        return path.format_map(self.namespaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = XMLNamespaces(cr='http://www.w3.org/1999')\n",
    "doc.find(ns('stop/{cr}cr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relational database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('database.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f3925ee3180>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = db.cursor()\n",
    "c.execute('create table portfolio(symbol text, shares integer, price real)')\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f3925ee3180>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks=[\n",
    "    ('GOOG', 100, 12.2),\n",
    "    ('AAPL', 101, 1.2),\n",
    "    ('FB', 400, 1.2),\n",
    "    ('HPQ', 10, 12.2),\n",
    "]\n",
    "\n",
    "c.executemany('insert into portfolio values(?,?,?)', stocks)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('GOOG', 100, 120.2)\n",
      "('AAPL', 100, 120.2)\n",
      "('FB', 100, 120.2)\n",
      "('HPQ', 100, 120.2)\n",
      "('GOOG', 100, 120.2)\n",
      "('AAPL', 101, 120.2)\n",
      "('FB', 400, 120.2)\n",
      "('HPQ', 10, 120.2)\n",
      "('GOOG', 100, 12.2)\n",
      "('AAPL', 101, 1.2)\n",
      "('FB', 400, 1.2)\n",
      "('HPQ', 10, 12.2)\n"
     ]
    }
   ],
   "source": [
    "for row in db.execute('select * from portfolio'):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('GOOG', 100, 120.2)\n",
      "('AAPL', 100, 120.2)\n",
      "('FB', 100, 120.2)\n",
      "('HPQ', 100, 120.2)\n",
      "('GOOG', 100, 120.2)\n",
      "('AAPL', 101, 120.2)\n",
      "('FB', 400, 120.2)\n",
      "('HPQ', 10, 120.2)\n"
     ]
    }
   ],
   "source": [
    "min_price = 100\n",
    "for row in db.execute('select * from portfolio where price >= ?', (min_price,)): \n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16 encoding/decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = b'hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'68656c6c6f'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import binascii\n",
    "h = binascii.b2a_hex(s)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binascii.a2b_hex(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'68656C6C6F'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "h = base64.b16encode(s)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base64.b16decode(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'68656C6C6F'\n",
      "68656C6C6F\n"
     ]
    }
   ],
   "source": [
    "h = base64.b16encode(s)\n",
    "print(h)\n",
    "print(h.decode('ascii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코딩 함수는 바이트 문자열이다. 반드시 유니코드를 사용해야 한다면 디코딩 과정을 하나더 추가하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base64 encoding/decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = b'hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'aGVsbG8='"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "b = base64.b64encode(s)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base64.b64decode(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aGVsbG8='"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base64.b64encode(s).decode('ascii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문자열로 출력이 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# struct\n",
    "* 바이너리 배열 구조체를 튜플로 만들기 struct 로 튜플을 인코딩하는 식으로 파이썬 바이너리 파일에 씀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from struct import Struct\n",
    "\n",
    "def write_records(records, format, f):\n",
    "    '''일련의 튜플을 구조체의 바이너리 파일에 기록'''\n",
    "    record_struct = Struct(format)\n",
    "    for r in records:\n",
    "        f.write(record_struct.pack(*r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [\n",
    "    (1,2.4,10),\n",
    "    (4,2.5,11),\n",
    "    (2,2.0,10),\n",
    "]\n",
    "\n",
    "with open('data.b', 'wb') as f:\n",
    "    write_records(records, '<idd', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from struct import Struct \n",
    "\n",
    "# 조각으로 읽기 \n",
    "def read_records(format, f):\n",
    "    record_struct = Struct(format)\n",
    "    chunks = iter(lambda: f.read(record_struct.size), b'')\n",
    "    return (record_struct.unpack(chunk) for chunk in chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2.4, 10.0)\n",
      "(4, 2.5, 11.0)\n",
      "(2, 2.0, 10.0)\n"
     ]
    }
   ],
   "source": [
    "with open('data.b', 'rb') as f:\n",
    "    for rec in read_records('<idd', f):\n",
    "        print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한꺼번에 읽기\n",
    "def unpack_records(format, dat):\n",
    "    record_struct = Struct(format)\n",
    "    return (record_struct.unpack_from(data, offset)\n",
    "           for offset in range(0, len(data), record_struct.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2.4, 10.0)\n",
      "(4, 2.5, 11.0)\n",
      "(2, 2.0, 10.0)\n"
     ]
    }
   ],
   "source": [
    "with open('data.b', 'rb') as f:\n",
    "    data = f.read()\n",
    "\n",
    "for rec in unpack_records('<idd', data):\n",
    "    print(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i, d, f 와 같은 코드를 사용해 구조체를 정의하고 32비트 정수, 64비트 부동 소수, 32비트 부동 소수를 가리킨다. <br>\n",
    "< 리틀엔디안 > 빅엔지안이 되고 ! 로 바꾸면 네트쿼으 바이트 순서가 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from struct import Struct \n",
    "record_struct = Struct('<idd')\n",
    "record_struct.size # 구조체의 크기를 바이트로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x80A@\\x00\\x00\\x00\\x00\\x00\\x00\\x00@'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_struct.pack(1, 35, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 35.0, 2.0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_struct.unpack(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 중첩가변 바이너리 구조체 읽기 \n",
    "\n",
    "중첩되었거나 크기가 변하는 레코드 컬렉션으로 이루어진 바이너리 인코딩 데이터를 읽어야 할떄 (이미지, 비디오, 셰이프 파일등)\n",
    "\n",
    "skip...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas \n",
    "* 데이터 요약과 통계 수행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiny/.local/lib/python3.5/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "rats = pandas.read_csv('rats.csv', skipfooter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rats['status'].unique()\n",
    "crew_dispatched = rats[rats['status']==1]\n",
    "len(crew_dispatched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32    3\n",
       "30    2\n",
       "20    2\n",
       "43    2\n",
       "42    2\n",
       "6     2\n",
       "40    2\n",
       "39    2\n",
       "7     2\n",
       "13    2\n",
       "Name: litter, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crew_dispatched['litter'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = crew_dispatched.groupby('status')\n",
    "len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "1    39\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_counts = dates.size()\n",
    "date_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_counts.sort()\n",
    "# date_counts[-10:`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
